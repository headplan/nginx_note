# Nginx的请求切换

前面提到了Nginx是如何使用epoll来运行自己的事件驱动框架的 , 这样的事件驱动框架带来怎样的好处 ? 下面来看一下在请求切换的应用场景中 , 事件驱动框架的应用 .

![](/assets/qingqiuqiehuan.png)

在上图中 , 实际上有三个请求 , 分别是蓝色 , 绿色和橘黄色的 . 假设每个请求都是http请求 , 简化为三部分 . 比如第一部分 , 接收到HTTP请求的header , 接收到header以后 , 利用一些负载均衡算法 , 应该就知道要交给上游的哪一台服务器去处理了 . 接下来就会和上游服务器建立连接 . 或者说本地处理的时候 , 接下来会去判断header中是否有content-length , 指明它还有body体 . 如果有body的话 , 接下来的读事件会去处理HTTP body , 处理完HTTP body之后可能还会发送一个HTTP响应 , 这样一个过程中 , 经历了三个事件 .

传统的服务 , 比如Apache , Tomcat , 每一个进程同一时间只处理一个请求 . 比如 , 上图左侧的process1 , 在处理request1的时候 , 在网络事件不满足的时候 , 就会切换到process2 , 去处理上面的request2 , 这是request2可能很快又不满足了 , 比如想写一个响应的时候 , 发现写缓存区域已经满了 , 也就是说网络中已经比较拥塞了 , 所以滑动窗口没有向前滑动 , 以至于调用write方法没有办法写入需要的字节 , 即使是当write方法为非阻塞的时候 . 

这个时候 , 阻塞类的write方法 , 一定会导致进程又发生一次切换 , 也就是切换到了process3上 , 操作系统选择了process3 , 因为其request3处于满足状态 , 可以继续向下执行 , 执行了一段时间后 , process3用完了它的时间片 , 又被操作系统切换到了process1 , 如此往复下去 . 

上面的流程显示出了一个问题 , 绿色箭头没做一次切换 , 在当前CPU的频率下 , 所消耗的时间 , 大于是5微妙的话 , 这里的5微妙虽然很小 , 但是如果并发的连接和并发的进程数 , 开始增加的时候 , 它不是一个线性增加 , 而是指数级的增加 . 所以当并发连接非常多的时候 , 进程间的消耗也会随之剧增 , 以至于消耗了大部分的计算能力 , 所以传统的web服务 , 依赖操作系统的进程调度方法 , 去实现并发连接 , 而操作系统的进程调度仅仅适用于少量的 , 数百上千的进程间切换 , 相对来说 , 进程间消耗的成本还能够接受 . 当量级达到几万 , 几十万的情况下 , 就无法接受了 . 

