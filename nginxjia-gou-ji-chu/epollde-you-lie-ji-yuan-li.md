# epoll的优劣及原理

前面提到了Nginx的事件分发机制 , 在循环流程中 , 最关键的是Nginx怎样能够 , 快速的从操作系统的kernel中获取到等待处理的事件 . 这样一个简单的步骤 , 其实经历了很长时间才解决 . 现在 , Nginx通过使用epoll这样一个网络事件收集器模型解决了这个问题 .

> epoll是Linux内核为处理大批量文件描述符而作了改进的poll , 是Linux下多路复用IO接口select/poll的增强版本 , 它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率 . 另一点原因就是获取事件的时候 , 它无须遍历整个被侦听的描述符集 , 只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了 .

![](/assets/libevent_benchmark.png)

从上图可以看出 , epoll与句柄数的增加基本是无关的 , 所以性能会好很多 , 而且非常适合做大并发连接的处理 . 下面看一下应用场景 ,比如 , Nginx要处理100W个连接 , 在之前的事件分发图中可以看到 , 每两次做等待新的连接中 , 时间可能会非常的短 , 在短短的几百毫秒这样的一个量级的时间中 , 所能收到的报文数量是有限的 , 而这些有限的事件所对应的连接也是有限的 , 也就是每次处理事件时 , 虽然总共有100W个并发连接 , 但可能只接受到几百个活跃的连接 , 只需要处理几百个活跃的请求 .

![](/assets/1111122222.png)

而Select或者Poll的实现是有问题的 , 因为每一次去取操作系统的事件时 , 都需要把这100W个连接都扔给操作系统 , 让它去依次的判断哪些连接上有事件进来了 . 所以可以看到 , 操作系统做了大量的无用功 , 其扫描了大量不活跃的连接 . 而epoll就使用了这样一个特性 , 因为每次处理的活跃连接数量占比很小 .

上图可以看到 , 活跃的连接维护了一个eventpoll , 通过两个数据结构链表和红黑树 , 把活跃和不活跃两件事分开了 , 也就是说Nginx每次取活跃连接的时候 , 只需要去遍历一个链表 , 这个链表里仅仅只有活跃的链接 , 这样的话效率就非常的高 . 还会用到红黑树 . 例如 , Nginx收到80端口建立的连接请求 , 建立成功以后 , 要添加一个读事件 , 这个读事件是用来读取HTTP消息的 , 这个时候可能会添加一个新的事件 , 可能是写事件添加进来 , 这个时候添加的就会放到红黑树中 , 这样一个二叉平衡树能保证插入时的效率是O\(log n\) . 如果现在不想再处理读事件或者写事件 , 只需要从这个平衡二叉树中移除一个节点就可以了 , 复杂度同样是O\(log n\) , 效率也是非常高的 . 

再看看链表的增减 , 前面提到了 , 读取一个事件的时候 , 也就是获取句柄的时候 , 只是去遍历rdllink , 就是遍历准备好的连接 , 读取到就没了 . 从内核态到用户态 , 只读取一点点东西 , 效率非常的高 . 当操作系统接收到网卡中发送来的报文的时候 , 这个链表就会增加一个新的元素 , 操作也是非常快的 . 

