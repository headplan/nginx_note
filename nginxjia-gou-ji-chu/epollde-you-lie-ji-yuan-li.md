# epoll的优劣及原理

前面提到了Nginx的事件分发机制 , 在循环流程中 , 最关键的是Nginx怎样能够 , 快速的从操作系统的kernel中获取到等待处理的事件 . 这样一个简单的步骤 , 其实经历了很长时间才解决 . 现在 , Nginx通过使用epoll这样一个网络事件收集器模型解决了这个问题 .

> epoll是Linux内核为处理大批量文件描述符而作了改进的poll , 是Linux下多路复用IO接口select/poll的增强版本 , 它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率 . 另一点原因就是获取事件的时候 , 它无须遍历整个被侦听的描述符集 , 只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了 .

![](/assets/libevent_benchmark.png)

从上图可以看出 , epoll与句柄数的增加基本是无关的 , 所以性能会好很多 , 而且非常适合做大并发连接的处理 . 下面看一下应用场景 ,比如 , Nginx要处理100W个连接 , 在之前的事件分发图中可以看到 , 每两次做等待新的连接中 , 时间可能会非常的短 , 在短短的几百毫秒这样的一个量级的时间中 , 所能收到的报文数量是有限的 , 而这些有限的事件所对应的连接也是有限的 , 也就是每次处理事件时 , 虽然总共有100W个并发连接 , 但可能只接受到几百个活跃的连接 , 只需要处理几百个活跃的请求 .

![](/assets/1111122222.png)

而Select或者Poll的实现是有问题的 , 因为每一次去取操作系统的事件时 , 都需要把这100W个连接都扔给操作系统 , 让它去依次的判断哪些连接上有事件进来了 . 所以可以看到 , 操作系统做了大量的无用功 , 其扫描了大量不活跃的连接 . 而epoll就使用了这样一个特性 , 因为每次处理的活跃连接数量占比很小 .

